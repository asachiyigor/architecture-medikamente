# Задание 6. Движок классификации данных

## 1. Описание решения

Движок классификации данных — это компонент аналитического слоя, который автоматически определяет уровень конфиденциальности данных перед их пакетной загрузкой в аналитическое хранилище (ClickHouse). Движок обрабатывает входящие данные различных структур, присваивает им теги конфиденциальности и маршрутизирует в соответствующие слои хранилища.

### Ключевые требования
- Данные на входе **не размечены** по классам конфиденциальности
- Структуры данных **подвержены изменениям** (schema evolution)
- Часть данных может содержать **конфиденциальную информацию** (ПДн, PHI)
- Необходимо обеспечить соответствие принципам **Privacy by Design**

---

## 2. Архитектура движка (описание C2-диаграммы)

Диаграмма C2 (Container) представлена в файле `classification-engine-c2.drawio`.

### Контейнеры движка:

| Контейнер | Технология | Назначение |
|-----------|-----------|-----------|
| **Data Ingestion Gateway** | Apache NiFi | Точка входа данных. Приём пакетных данных из различных источников (PostgreSQL, 1С, файлы). Первичная нормализация формата. |
| **Schema Registry** | Confluent Schema Registry | Хранение и версионирование схем данных. Определение изменений в структуре (schema evolution). |
| **Classification Engine Core** | Java (Spring Boot) | Основной модуль классификации. Использует правила и ML-модель для определения класса конфиденциальности каждого поля/записи. |
| **Rules Engine** | Drools / OPA | Набор детерминированных правил классификации (regex-паттерны для ПДн, словари медицинских терминов, шаблоны платёжных данных). |
| **ML Classifier** | Python (scikit-learn / spaCy) | ML-модель для классификации неструктурированных и текстовых данных (NER для выявления имён, диагнозов, адресов). |
| **Tag Manager** | Apache Atlas API | Присвоение тегов конфиденциальности данным. Хранение метаданных и связей между тегами. |
| **Data Router** | Apache NiFi | Маршрутизация размеченных данных в соответствующие слои хранилища на основе присвоенных тегов. |
| **Quality Gate** | Java (Spring Boot) | Контроль качества классификации. Проверка полноты разметки. Алерты при обнаружении неклассифицированных данных. |
| **Audit Logger** | ELK Stack | Логирование всех операций классификации для аудита и compliance. |

### Слои аналитического хранилища (ClickHouse):

| Слой | Назначение | Уровень доступа | Данные |
|------|-----------|----------------|--------|
| **Raw Layer (Staging)** | Временное хранение входящих данных до классификации | Только движок классификации | Все входящие данные в исходном формате |
| **Sensitive Layer** | Хранение данных, содержащих ПДн/PHI | Только авторизованные сервисы (ABAC) | Классифицированные данные с тегами CONFIDENTIALITY:HIGH/CRITICAL |
| **Anonymized Layer** | Обезличенные данные для аналитики | Аналитики, BI, ML | Данные после псевдонимизации/k-анонимизации, без прямых идентификаторов |
| **Aggregated Layer** | Агрегированные статистические данные | Широкий доступ | Агрегаты, невозможно восстановить индивидуальные записи |

### Дополнительные меры:
- **Quarantine Zone** — отдельное хранилище для данных, которые движок не смог однозначно классифицировать. Data Steward вручную проверяет и размечает такие данные.
- **Encryption at Rest** — все слои хранилища зашифрованы (AES-256)
- **Row-Level Security** — доступ к данным в Sensitive Layer контролируется на уровне строк
- **Data Retention Policies** — автоматическое удаление данных из Raw Layer через 72 часа после обработки

---

## 3. Метрики эффективности классификации

### 3.1 Метрики качества классификации

| Метрика | Описание | Целевое значение | Как помогает оптимизации |
|---------|----------|-----------------|------------------------|
| **Precision (точность)** | Доля правильно классифицированных конфиденциальных данных среди всех помеченных как конфиденциальные | >= 95% | Минимизирует ложные срабатывания — меньше данных попадает в Quarantine, снижая нагрузку на Data Steward |
| **Recall (полнота)** | Доля найденных конфиденциальных данных среди всех реально конфиденциальных | >= 99% | Критически важно — пропущенные ПДн могут попасть в открытый аналитический слой. Высокий recall гарантирует compliance |
| **F1-Score** | Гармоническое среднее Precision и Recall | >= 97% | Баланс между точностью и полнотой — показатель общего качества модели |
| **Quarantine Rate** | Процент данных, направленных в Quarantine | < 5% | Высокий показатель указывает на необходимость расширить правила или дообучить модель |
| **False Negative Rate** | Процент конфиденциальных данных, ошибочно пропущенных | < 1% | Критическая метрика безопасности. При росте — немедленная ревизия правил. |
| **Processing Latency** | Время классификации одного пакета данных | < 30 секунд на 10 000 записей | Оптимизация пропускной способности для масштабирования |
| **Schema Evolution Adaptability** | Процент новых полей, успешно классифицированных без изменения правил | >= 80% | Показывает robustness модели к изменениям структуры данных |

### 3.2 Операционные метрики

| Метрика | Описание | Целевое значение |
|---------|----------|-----------------|
| **Throughput** | Количество записей, обработанных в единицу времени | >= 100 000 записей/час |
| **Error Rate** | Процент ошибок при обработке пакетов | < 0.1% |
| **Availability** | Доступность движка | >= 99.9% |
| **Manual Review Time** | Среднее время ручной проверки записи из Quarantine | < 2 минут |

### 3.3 Как метрики помогают оптимизации

1. **Непрерывное обучение:** Данные из Quarantine, проверенные Data Steward, используются для дообучения ML-модели, повышая Precision и снижая Quarantine Rate.
2. **A/B-тестирование правил:** Новые правила классификации тестируются на исторических данных. Сравниваются F1-Score старых и новых правил.
3. **Мониторинг дрейфа:** Tracking изменений в распределении тегов позволяет выявить изменения в характере данных и адаптировать модель.
4. **Оптимизация ресурсов:** Processing Latency и Throughput показывают, нужно ли горизонтальное масштабирование.

---

## 4. Масштабируемость (Scalability)

### 4.1 Горизонтальное масштабирование

| Компонент | Стратегия масштабирования | Механизм |
|-----------|--------------------------|----------|
| **Data Ingestion Gateway** | Добавление NiFi-нод в кластер | NiFi кластерный режим — автоматическое распределение нагрузки |
| **Classification Engine Core** | Horizontal Pod Autoscaler (HPA) в Kubernetes | При росте CPU > 70% — создание новых подов. Stateless-сервис — легко масштабируется. |
| **ML Classifier** | Отдельный пул подов с GPU (при необходимости) | HPA на основе длины очереди задач классификации |
| **Rules Engine** | Stateless — масштабируется вместе с Core | Правила загружаются из конфигурации при старте |
| **Data Router** | NiFi кластер | Параллельная маршрутизация по нескольким потокам |
| **ClickHouse** | Шардирование + репликация | Добавление шардов при росте объёма; ReplicatedMergeTree для отказоустойчивости |
| **Apache Atlas** | Кластерный режим (Atlas + HBase + Solr) | Горизонтальное масштабирование хранилища метаданных |

### 4.2 Стратегия масштабирования при росте

**Текущий масштаб:** 1 офис, ~35 сотрудников, ~1000 пациентов/мес.

**5-кратный рост:** 5 филиалов, ~175 сотрудников, ~5000 пациентов/мес.

| Параметр | Текущий | 5x рост | Стратегия |
|----------|---------|---------|-----------|
| **Объём данных** | ~10 GB/мес | ~50 GB/мес | ClickHouse шардирование (2 → 5 шардов) |
| **Записи для классификации** | ~50 000/мес | ~250 000/мес | HPA: 2 → 5 подов Classification Engine |
| **Количество источников** | 4 (Excel, 1С x2, общий диск) | 15+ (порталы, API, филиалы) | NiFi кластер: 1 → 3 ноды |
| **Пользователи аналитики** | 1 (аналитик) | 5-10 | ClickHouse реплики для read-нагрузки |
| **Филиалы** | 1 | 5 | Федеративная архитектура: локальный сбор + централизованная классификация |

### 4.3 Архитектурные решения для масштабируемости

1. **Event-driven architecture:** Между компонентами — Apache Kafka для буферизации и гарантированной доставки. При росте нагрузки — добавление партиций.

2. **Stateless сервисы:** Classification Engine Core и Rules Engine не хранят состояние — легко масштабируются добавлением подов.

3. **Кэширование:** Redis для кэширования результатов классификации повторяющихся паттернов — снижает нагрузку на ML-модель.

4. **Партиционирование данных:** ClickHouse с партиционированием по дате и филиалу — ускорение запросов при росте объёма.

5. **Multi-tenant:** Каждый филиал — отдельный tenant. Изоляция данных на уровне Row-Level Security. Централизованная классификация.
